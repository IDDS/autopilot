package scheduler

import (
    "context"
    "fmt"
    "reflect"
    "time"

    "github.com/go-logr/logr"
    "github.com/golang/protobuf/ptypes"

    "k8s.io/apimachinery/pkg/api/errors"
    "k8s.io/kubernetes/pkg/util/slice"

    ctl "sigs.k8s.io/controller-runtime/pkg/client"
    "sigs.k8s.io/controller-runtime/pkg/handler"
    "sigs.k8s.io/controller-runtime/pkg/manager"
    "sigs.k8s.io/controller-runtime/pkg/reconcile"

    "github.com/solo-io/autopilot/pkg/config"
    "github.com/solo-io/autopilot/pkg/ezkube"
{{- if needs_metrics }}
    "github.com/solo-io/autopilot/pkg/metrics"
{{- end}}
    "github.com/solo-io/autopilot/pkg/scheduler"
    "github.com/solo-io/autopilot/pkg/utils"

    {{$.Version}} "{{$.TypesImportPath}}"

{{- if needs_metrics }}
    {{$.KindLower}}metrics "{{$.MetricsImportPath}}"
{{- end}}

{{- if $.EnableFinalizer }}
    finalizer "{{.FinalizerImportPath}}"
{{- end}}

{{- range $phase := .Phases }}
    {{- range $param := $phase.Outputs }}
    {{$param.ImportPrefix}} "{{$param.Package}}"
    {{- end}}
{{- end}}

{{- range $phase := .Phases}}
    {{- if not $phase.Final }}
    {{worker_import_prefix $phase}} "{{worker_package $phase}}"
    {{- end}}
{{- end}}
)

func AddToManager(params scheduler.Params) error {
    scheduler, err := NewScheduler(params)
    if err != nil {
    	return err
    }
    // Create a new controller
    c, err := controller.New("{{.KindLowerCamel}}-controller", params.Manager, controller.Options{Reconciler: scheduler})
    if err != nil {
        return err
    }

    // Watch for changes to primary resource {{.Kind}}
    params.Logger.Info("Registering watch for primary resource {{.Kind}}")
    err = c.Watch(&source.Kind{Type: &{{$.Version}}.{{$.Kind}}{}}, &handler.EnqueueRequestForObject{})
    if err != nil {
        return err
    }

{{- range $param := unique_outputs }}

    // Watch for changes to output resource {{$param.PluralName }} and requeue the owner {{$.Kind}}
    params.Logger.Info("Registering watch for output resource {{$param.PluralName }}")
    err = c.Watch(&source.Kind{Type: &{{$param.ImportPrefix }}.{{$param.SingleName }}{}}, &handler.EnqueueRequestForOwner{
        IsController: true,
        OwnerType:    &{{$.Version}}.{{$.Kind}}{},
    })
    if err != nil {
        return err
    }
{{- end}}

    return nil

}

{{- if $.EnableFinalizer }}
var FinalizerName = "{{$.KindLower}}-finalizer"
{{- end}}

type Scheduler struct {
    ctx context.Context
    mgr manager.Manager
    namespace string
    logger logr.Logger
{{- if needs_metrics }}
    metrics {{$.KindLower}}metrics.{{$.Kind}}Metrics
{{- end}}
    workInterval time.Duration
}

func NewScheduler(params scheduler.Params) (*Scheduler, error) {
	cfg := config.ConfigFromContext(params.Ctx)

    workInterval, err := ptypes.Duration(cfg.WorkInterval)
    if err != nil {
    	return nil, err
    }

{{- if needs_metrics }}
    metricsServer := metrics.GetMetricsServerAddr(cfg.MeshProvider, cfg.ControlPlaneNs)
    metricsBase, err := metrics.NewPrometheusClient(metricsServer)
    if err != nil {
    	return nil, err
    }
    metricsClient := {{.KindLower}}metrics.NewMetricsClient(metricsBase)
{{- end}}

    return &Scheduler{
    	ctx:       params.Ctx,
    	mgr:       params.Manager,
        namespace: params.Namespace,
        logger:    params.Logger,
    	workInterval: workInterval,
{{- if needs_metrics }}
        metrics:   metricsClient,
{{- end}}
    }, nil
}

func (s *Scheduler) Reconcile(request reconcile.Request) (reconcile.Result, error) {
    result := reconcile.Result{RequeueAfter: s.workInterval}

    {{$.KindLowerCamel}} := &{{$.Version}}.{{$.Kind}}{}
    {{$.KindLowerCamel}}.Namespace = request.Namespace
    {{$.KindLowerCamel}}.Name = request.Name

    client := ezkube.NewClient(s.mgr)

    if err := client.Get(s.ctx, {{$.KindLowerCamel}}); err != nil {
        // garbage collection and finalizers should handle cleaning up after deletion
        if errors.IsNotFound(err) {
            return result, nil
        }
        return result, fmt.Errorf("failed to retrieve requested {{$.Kind}}: %v", err)
    }

    {{- if $.EnableFinalizer }}
    // examine DeletionTimestamp to determine if object is under deletion
    if {{$.KindLowerCamel}}.DeletionTimestamp.IsZero() {
        // The object is not being deleted, so if it does not have our finalizer,
        // then lets add the finalizer and update the object. This is equivalent
        // registering our finalizer.
        if !utils.ContainsString({{$.KindLowerCamel}}.Finalizers, FinalizerName) {
            {{$.KindLowerCamel}}.Finalizers = append({{$.KindLowerCamel}}.Finalizers, FinalizerName)
            if err := client.Ensure(s.ctx, nil, {{$.KindLowerCamel}}); err != nil {
                return result, fmt.Errorf("failed to add finalizer: %v", err)
            }
        }
    } else {
        // The object is being deleted
        if utils.ContainsString({{$.KindLowerCamel}}.Finalizers, FinalizerName) {
            // our finalizer is present, so lets handle any external dependency
            if err := (&finalizer.Finalizer{Client: client}).Finalize(s.ctx, {{$.KindLowerCamel}}); err != nil {
                // if fail to delete the external dependency here, return with error
                // so that it can be retried
                return result, fmt.Errorf("failed to run finalizer: %v", err)
            }

            // remove our finalizer from the list and update it.
            {{$.KindLowerCamel}}.Finalizers = utils.RemoveString({{$.KindLowerCamel}}.Finalizers, FinalizerName)
            if err := client.Ensure(s.ctx, nil, {{$.KindLowerCamel}}); err != nil {
                return result, fmt.Errorf("failed to remove finalizer: %v", err)
            }
        }

        return result, nil
    }
    {{- end}}

    // store original status for comparison after sync
    status :=  {{$.KindLowerCamel}}.Status

    logger := s.logger.WithValues(
        "{{$.KindLowerCamel}}", {{$.KindLowerCamel}}.Namespace+"."+{{$.KindLowerCamel}}.Name,
        "phase", {{$.KindLowerCamel}}.Status.Phase,
    )

    switch {{$.KindLowerCamel}}.Status.Phase {
{{- range $phase := .Phases}}
    {{- if $phase.Initial }}
    case "", {{$.Version}}.{{$.Kind}}Phase{{$phase.Name}}:
    {{- else }}
    case {{$.Version}}.{{$.Kind}}Phase{{$phase.Name}}:
    {{- end}}

{{- if $phase.Final }}
        logger.Info("{{$.Kind}} is in final phase {{$phase.Name}}. Removing from queue.", "name", {{$.KindLowerCamel}}.Name)

        // {{$phase.Name}} is a final phase, do not requeue
        result.RequeueAfter = 0

{{- else }} // begin worker phase
        logger.Info("Syncing {{$.Kind}} in phase {{$phase.Name}}", "name", {{$.KindLowerCamel}}.Name)

        worker := &{{worker_import_prefix $phase}}.Worker{
        	Client: client,
        	Logger: logger,
        }

    {{- if has_inputs $phase }}
		inputs, err := s.make{{ $phase.Name}}Inputs(client)
		if err != nil {
			return result, fmt.Errorf("failed to make {{ $phase.Name}}Inputs: %v", err)
		}

        {{- if has_outputs $phase }}
        outputs, nextPhase, statusInfo, err := worker.Sync(s.ctx, {{$.KindLowerCamel}}, inputs)
		if err != nil {
			return result, fmt.Errorf("failed to run worker for phase {{ $phase.Name}}: %v", err)
		}
        {{- else}}
        nextPhase, statusInfo, err := worker.Sync(s.ctx, {{$.KindLowerCamel}}, inputs)
		if err != nil {
            return result, fmt.Errorf("failed to run worker for phase {{ $phase.Name}}: %v", err)
		}

        {{- end}}

        {{- else}}
        {{- if has_outputs $phase }}
        outputs, nextPhase, statusInfo, err := worker.Sync(s.ctx, {{$.KindLowerCamel}})
		if err != nil {
           return result, fmt.Errorf("failed to run worker for phase {{ $phase.Name}}: %v", err)
		}
        {{- else}}
        nextPhase, statusInfo, err := worker.Sync(s.ctx, {{$.KindLowerCamel}})
		if err != nil {
            return result, fmt.Errorf("failed to run worker for phase {{ $phase.Name}}: %v", err)
		}
        {{- end}}
    {{- end}}

    {{- range $out := $phase.Outputs }}
		for _, out := range outputs.{{ $out.PluralName }}.Items {
			if err := client.Ensure(s.ctx, {{$.KindLowerCamel}}, &out); err != nil {
                return result, fmt.Errorf("failed to write output {{ $out.SingleName }}<%v.%v> for phase {{ $phase.Name}}: %v", out.GetNamespace(), out.GetName(), err)
			}
		}
    {{- end}}

        // update the {{$.Kind}} status with the worker's results
        {{$.KindLowerCamel}}.Status.Phase = nextPhase
        if statusInfo != nil {
        	logger.Info("Updating status of primary resource")
            {{$.KindLowerCamel}}.Status.{{$.Kind}}StatusInfo = *statusInfo
        }

    {{- end}}


{{- end }} // end worker phase

    default:
        return result, fmt.Errorf("cannot process {{.Kind}} in unknown phase: %v", {{$.KindLowerCamel}}.Status.Phase)
    }

    {{$.KindLowerCamel}}.Status.ObservedGeneration = {{$.KindLowerCamel}}.Generation

    if !reflect.DeepEqual(status, {{$.KindLowerCamel}}.Status) {
        if err := client.UpdateStatus(s.ctx, {{$.KindLowerCamel}}); err != nil {
            return result, fmt.Errorf("failed to update {{$.Kind}}Status: %v", err)
        }
    }

    return result, nil
}

{{- range $phase := .Phases}}
    {{- if has_inputs $phase }}

func (s *Scheduler) make{{ $phase.Name}}Inputs(client ezkube.Client) ({{worker_import_prefix $phase}}.Inputs, error) {
	var (
		inputs {{worker_import_prefix $phase}}.Inputs
	    err error
    )

        {{- range $param := $phase.Inputs }}
            {{- if is_metrics $param }}
    inputs.{{$param.PluralName}} = s.metrics
            {{- else}}
    err = client.List(s.ctx, &inputs.{{$param.PluralName}}, ctl.InNamespace(s.namespace))
    if err != nil {
        return inputs, err
    }
            {{- end}}
        {{- end}}

    return inputs, err
}

{{- end}}
{{- end}}
